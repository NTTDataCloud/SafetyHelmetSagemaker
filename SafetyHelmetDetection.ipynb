{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::467343721842:role/service-role/AmazonSageMaker-ExecutionRole-20200521T183987\n",
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/object-detection:latest\n",
      "CPU times: user 649 ms, sys: 76.2 ms, total: 725 ms\n",
      "Wall time: 761 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = 'safetyhelmettestbucket' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'objectDetection'\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf train\n",
    "rm -rf train_annotation\n",
    "rm -rf val\n",
    "rm -rf val_annotation\n",
    "mkdir train\n",
    "mkdir train_annotation\n",
    "mkdir val\n",
    "mkdir val_annotation\n",
    "cp JPEGImages/* train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "mypath = \"Annotations\"\n",
    "jsonpath = \"train_annotation\"\n",
    "\n",
    "files = listdir(mypath)\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    fullfilename = mypath + '/' + f\n",
    "    jsonfullfilename = jsonpath + '/' + f.replace(\"xml\",\"json\")\n",
    "    line = {}\n",
    "    \n",
    "    tree = ET.ElementTree(file=fullfilename)\n",
    "    root = tree.getroot()\n",
    "    categories = {}\n",
    "    for child in root:\n",
    "        if child.tag == \"filename\":\n",
    "            line[\"file\"] = f.replace(\"xml\",\"jpg\")\n",
    "        if child.tag == \"size\":\n",
    "            line[\"image_size\"] = []\n",
    "            image_size = {}\n",
    "            for s in child:\n",
    "                if s.tag == \"width\":\n",
    "                    image_size[\"width\"] = int(s.text)\n",
    "                elif s.tag == \"height\":\n",
    "                    image_size[\"height\"] = int(s.text)\n",
    "                elif s.tag == \"depth\":\n",
    "                    image_size[\"depth\"] = int(s.text)\n",
    "                else:\n",
    "                    print(s.tag,\":\",s.text)\n",
    "        \n",
    "            line[\"image_size\"].append(image_size)\n",
    "            line[\"annotations\"] = []            \n",
    "            line[\"categories\"] = []\n",
    "            \n",
    "        if child.tag == \"object\":\n",
    "            annotation = {}\n",
    "            for s in child:                           \n",
    "                if s.tag == \"bndbox\": \n",
    "                    left = 0\n",
    "                    right = 0\n",
    "                    top = 0\n",
    "                    bottom = 0\n",
    "                    for ss in s:\n",
    "                        if ss.tag == \"xmin\":\n",
    "                            left = int(ss.text)\n",
    "                        elif ss.tag == \"xmax\":\n",
    "                            right = int(ss.text)\n",
    "                        elif ss.tag == \"ymin\":\n",
    "                            top = int(ss.text)\n",
    "                        elif ss.tag == \"ymax\":\n",
    "                            bottom = int(ss.text)\n",
    "                    annotation[\"left\"] = left\n",
    "                    annotation[\"top\"] = top\n",
    "                    annotation[\"width\"] = right - left\n",
    "                    annotation[\"height\"] = bottom - top\n",
    "                if s.tag == \"name\":\n",
    "                    category = {}\n",
    "                    if s.text == \"hat\":\n",
    "                        annotation[\"class_id\"] = 0\n",
    "                    elif s.text == \"person\":\n",
    "                        annotation[\"class_id\"] = 1\n",
    "                    else:\n",
    "                        annotation[\"class_id\"] = 0\n",
    "            line[\"annotations\"].append(annotation)\n",
    "    line[\"categories\"].append({\"class_id\": 0, \"name\": \"hat\"})\n",
    "    line[\"categories\"].append({\"class_id\": 1, \"name\": \"person\"})\n",
    "            \n",
    "    if len(line[\"annotations\"]) > 0 :\n",
    "        with open(jsonfullfilename,\"w\") as p:\n",
    "            json.dump(line,p)\n",
    "    else:\n",
    "        os.remove('train/' + f.replace(\"xml\",\"jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "json_files = os.listdir('train_annotation')\n",
    "\n",
    "m = 4\n",
    "i = 0\n",
    "for f in json_files:\n",
    "    i = i + 1\n",
    "    jpgPath = 'train/' + f.replace(\"json\", \"jpg\");\n",
    "    if not os.path.exists(jpgPath):\n",
    "        os.rename('train/' + f.replace(\"json\", \"JPG\"), jpgPath)\n",
    "    if i%m == 0:\n",
    "        shutil.move(jsonpath + '/' + f, 'val_annotation/')\n",
    "        filePath = f.replace(\"json\",\"jpg\")\n",
    "        shutil.move('train/' + filePath, 'val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5686 files in training folder.\n",
      "1895 files in val folder.\n"
     ]
    }
   ],
   "source": [
    "print ( \"%d files in training folder.\" % len(os.listdir('train')))\n",
    "print ( \"%d files in val folder.\" % len(os.listdir('val')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='val', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='val_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=2,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=75,\n",
    "                             learning_rate=0.01,\n",
    "                             lr_scheduler_step='20,35,50',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=2000,\n",
    "                             num_training_samples=5686)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data, \n",
    "                 'train_annotation': train_annotation, 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = [\"green\",\"yellow\",\"red\"]\n",
    "\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "\n",
    "            if cls_id == 0 or cls_id == 2:       \n",
    "                xmin = int(x0 * width)\n",
    "                ymin = int(y0 * height)\n",
    "                xmax = int(x1 * width)\n",
    "                ymax = int(y1 * height)\n",
    "                rect = plt.Rectangle((xmin, ymin), \n",
    "                                     xmax - xmin,\n",
    "                                     ymax - ymin, \n",
    "                                     fill=False,\n",
    "                                     edgecolor=colors[cls_id],\n",
    "                                     linewidth=1.0)\n",
    "                plt.gca().add_patch(rect)\n",
    "                class_name = str(cls_id)\n",
    "                if classes and len(classes) > cls_id:\n",
    "                    class_name = classes[cls_id]\n",
    "                plt.gca().text(xmin, ymin - 2,\n",
    "                                '{:s} {:.3f}'.format(class_name, score),\n",
    "                                bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                        fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test/10.png'\n",
    "\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "    ne = open('n.txt','wb')\n",
    "    ne.write(b)\n",
    "\n",
    "object_detector.content_type = 'image/png'\n",
    "results = object_detector.predict(b)\n",
    "detections = json.loads(results)\n",
    "print (detections)\n",
    "object_categories = ['helmet', 'person']\n",
    "threshold = 0.05\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection(file_name, detections['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection_adv(img_file, filename, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = [\"green\",\"yellow\",\"red\"]\n",
    "        hasRect = False\n",
    "        \n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "\n",
    "            if cls_id == 0 or cls_id == 2:\n",
    "                hasRect = True\n",
    "                xmin = int(x0 * width)\n",
    "                ymin = int(y0 * height)\n",
    "                xmax = int(x1 * width)\n",
    "                ymax = int(y1 * height)\n",
    "                rect = plt.Rectangle((xmin, ymin), \n",
    "                                     xmax - xmin,\n",
    "                                     ymax - ymin, \n",
    "                                     fill=False,\n",
    "                                     edgecolor=colors[cls_id],\n",
    "                                     linewidth=1.0)\n",
    "                plt.gca().add_patch(rect)\n",
    "                class_name = str(cls_id)\n",
    "                if classes and len(classes) > cls_id:\n",
    "                    class_name = classes[cls_id]\n",
    "                plt.gca().text(xmin, ymin - 2,\n",
    "                                '{:s} {:.3f}'.format(class_name, score),\n",
    "                                bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                        fontsize=12, color='white')\n",
    "        if hasRect:\n",
    "            plt.savefig(filename)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf ava_gen\n",
    "mkdir ava_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listTestFiles = listdir(\"ava_test\")\n",
    "#listTestFiles = [\"rtsp-20200528-1056280600.png\"]\n",
    "for filename in listTestFiles:\n",
    "    fullFilePath = \"ava_test/\" + filename\n",
    "    altFullFilePath = \"ava_gen/\" + filename\n",
    "    with open(fullFilePath, 'rb') as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "        #ne = open('n.txt','wb')\n",
    "        #ne.write(b)\n",
    "\n",
    "        object_detector.content_type = 'image/png'\n",
    "        results = object_detector.predict(b)\n",
    "        detections = json.loads(results)\n",
    "        object_categories = ['helmet', 'person']\n",
    "        threshold = 0.6\n",
    "\n",
    "        # Visualize the detections.\n",
    "        visualize_detection_adv(fullFilePath, altFullFilePath, detections['prediction'], object_categories, threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "listGenFiles = listdir(\"ava_gen\")\n",
    "for filename in listGenFiles:\n",
    "    if filename != \".ipynb_checkpoints\":\n",
    "        altFullFilePath = \"ava_gen/\" + filename\n",
    "        with open(altFullFilePath, \"rb\") as f:\n",
    "            s3.upload_fileobj(f, \"kvs-img\", filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
